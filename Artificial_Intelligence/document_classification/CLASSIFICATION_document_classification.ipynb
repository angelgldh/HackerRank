{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.utils import resample\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This is a document</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>this is another document</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>documents are seperated by newlines</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              document\n",
       "0                  This is a document \n",
       "1            this is another document \n",
       "2  documents are seperated by newlines"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training data\n",
    "file_name = \"trainingdata.txt\"\n",
    "with open(file_name, 'r') as file:\n",
    "    data = file.read()\n",
    "raw_training_data = data.split(\"\\n\")\n",
    "# print(training_data)\n",
    "# # Testing data\n",
    "# data = sys.stdin.readlines()\n",
    "# testing_data = [line.rstrip() for line in data]\n",
    "\n",
    "testing_df = pd.read_csv('testing_data.txt')\n",
    "testing_df.columns = ['document']\n",
    "testing_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values:  label       0\n",
      "document    0\n",
      "dtype: int64\n",
      "Number of duplicated rows:  58\n",
      "Percentage of duplicated rows:  label       0.010574\n",
      "document    0.010574\n",
      "dtype: float64\n",
      "Label counts:\n",
      "1    2840\n",
      "2    1596\n",
      "6     253\n",
      "3     251\n",
      "8     206\n",
      "7     190\n",
      "4     108\n",
      "5      41\n",
      "Name: label, dtype: int64\n",
      "Label percentages:\n",
      "1    51.777575\n",
      "2    29.097539\n",
      "6     4.612580\n",
      "3     4.576117\n",
      "8     3.755697\n",
      "7     3.463993\n",
      "4     1.969006\n",
      "5     0.747493\n",
      "Name: label, dtype: float64\n",
      "Minimum document length: 30\n",
      "Maximum document length: 5295\n",
      "Average document length: 605.4659981768459\n",
      "Median document length: 375.0\n",
      "q1 document length: 165.0\n",
      "q3 document length: 686.0\n"
     ]
    }
   ],
   "source": [
    "# 1. Store it in the appropiate way -> panda data frame\n",
    "n_observations = int(raw_training_data[0].rstrip())\n",
    "\n",
    "pattern = r\"^\\d+\"\n",
    "\n",
    "training_list = []\n",
    "for i in range(1,n_observations+1):\n",
    "    input_str = raw_training_data[i]\n",
    "    \n",
    "    match = re.match(pattern, input_str)\n",
    "    row = list([int(match.group()), input_str[match.end()+1:]])\n",
    "    training_list.append(row)\n",
    "\n",
    "colnames = ['label', 'document']\n",
    "raw_training_df = pd.DataFrame(training_list, columns= colnames)\n",
    "raw_training_df[\"label\"].astype(int)\n",
    "\n",
    "dataset_inspection(raw_training_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_inspection(df):\n",
    "        # Missingness\n",
    "        missing_values = df.isnull().sum()\n",
    "        print('Missing values: ', missing_values)\n",
    "\n",
    "        # Duplicated rows\n",
    "        print('Number of duplicated rows: ', df.duplicated().sum())\n",
    "        print('Percentage of duplicated rows: ', (df.duplicated().sum() / df.apply(len)))\n",
    "\n",
    "        # Count and percentage per label\n",
    "        label_counts = df['label'].value_counts()\n",
    "        label_percentages = df['label'].value_counts(normalize=True) * 100\n",
    "        print('Label counts:')\n",
    "        print(label_counts)\n",
    "        print('Label percentages:')\n",
    "        print(label_percentages)\n",
    "\n",
    "        # Evaluate distribution of predictors\n",
    "        predictors = \"document\"\n",
    "        df['document_length'] = df[predictors].apply(len)\n",
    "        print('Minimum document length:', df['document_length'].min())\n",
    "        print('Maximum document length:', df['document_length'].max())\n",
    "        print('Average document length:', df['document_length'].mean())\n",
    "        print('Median document length:', df['document_length'].median())\n",
    "        print('q1 document length:', df['document_length'].quantile(0.25))\n",
    "        print('q3 document length:', df['document_length'].quantile(0.75))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clearly, the data set is umbalanced, let's reabalance it\n",
    "\n",
    "# Separate majority and minority classes\n",
    "df_majority = raw_training_df[(raw_training_df['label'] == 1)|(raw_training_df['label'] == 2)]\n",
    "df_minority = raw_training_df[(raw_training_df['label'] != 1) & (raw_training_df['label'] != 2)]\n",
    "\n",
    "# OPTION 1 : DOWNSAMPLE MAJORITY CLASS\n",
    "# Downsample majority class\n",
    "df_majority_downsampled = resample(df_majority,\n",
    "                                   replace=False,\n",
    "                                   n_samples=len(df_minority),\n",
    "                                   random_state=42)\n",
    "\n",
    "# Combine minority class with downsampled majority class\n",
    "df_downsampled = pd.concat([df_majority_downsampled, df_minority])\n",
    "\n",
    "\n",
    "# OPTION 2 : UPSAMPLE MINORITY CLASS\n",
    "# Upsample minority class\n",
    "df_minority_upsampled = resample(df_minority,\n",
    "                                 replace=True,\n",
    "                                 n_samples=len(df_majority)*3,\n",
    "                                 random_state=42)\n",
    "\n",
    "# Combine majority class with upsampled minority class\n",
    "df_upsampled = pd.concat([df_majority, df_minority_upsampled])\n",
    "\n",
    "\n",
    "# Let's try first with upsampling\n",
    "training_df = df_upsampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "def upsample_function(initial_df, minority_classes, target_size_per_class):\n",
    "        initial_df = raw_training_df\n",
    "\n",
    "        for c in minority_classes:\n",
    "                df_majority = initial_df[raw_training_df['label'] != c]\n",
    "                df_minority = initial_df[raw_training_df['label'] == c]\n",
    "\n",
    "                # Upsample minority class\n",
    "                df_minority_upsampled = resample(df_minority,\n",
    "                                                replace=True,\n",
    "                                                n_samples=round(target_size_per_class),\n",
    "                                                random_state=42)\n",
    "\n",
    "                # # Combine majority class with upsampled minority class\n",
    "                df_upsampled = pd.concat([df_majority, df_minority_upsampled])\n",
    "                initial_df = df_upsampled\n",
    "        return df_upsampled\n",
    "\n",
    "def downsample_function(initial_df, majority_classes, target_size_per_class):\n",
    "        initial_df = raw_training_df\n",
    "\n",
    "        for c in majority_classes:\n",
    "                df_majority = initial_df[raw_training_df['label'] == c]\n",
    "                df_minority = initial_df[raw_training_df['label'] != c]\n",
    "\n",
    "                # Downsample majority class\n",
    "                df_majority_downsampled = resample(df_majority,\n",
    "                                   replace=False,\n",
    "                                   n_samples=target_size_per_class,\n",
    "                                   random_state=42)\n",
    "\n",
    "                # Combine minority class with downsampled majority class\n",
    "                df_downsampled = pd.concat([df_majority_downsampled, df_minority])\n",
    "        return df_downsampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-163-237c6eac3e58>:10: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  df_majority = initial_df[raw_training_df['label'] != c]\n",
      "<ipython-input-163-237c6eac3e58>:11: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  df_minority = initial_df[raw_training_df['label'] == c]\n",
      "<ipython-input-163-237c6eac3e58>:10: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  df_majority = initial_df[raw_training_df['label'] != c]\n",
      "<ipython-input-163-237c6eac3e58>:11: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  df_minority = initial_df[raw_training_df['label'] == c]\n",
      "<ipython-input-163-237c6eac3e58>:10: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  df_majority = initial_df[raw_training_df['label'] != c]\n",
      "<ipython-input-163-237c6eac3e58>:11: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  df_minority = initial_df[raw_training_df['label'] == c]\n",
      "<ipython-input-163-237c6eac3e58>:10: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  df_majority = initial_df[raw_training_df['label'] != c]\n",
      "<ipython-input-163-237c6eac3e58>:11: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  df_minority = initial_df[raw_training_df['label'] == c]\n",
      "<ipython-input-163-237c6eac3e58>:10: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  df_majority = initial_df[raw_training_df['label'] != c]\n",
      "<ipython-input-163-237c6eac3e58>:11: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  df_minority = initial_df[raw_training_df['label'] == c]\n",
      "<ipython-input-163-237c6eac3e58>:10: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  df_majority = initial_df[raw_training_df['label'] != c]\n",
      "<ipython-input-163-237c6eac3e58>:11: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  df_minority = initial_df[raw_training_df['label'] == c]\n"
     ]
    }
   ],
   "source": [
    "minority_classes = [2,3,4,5,6,7,8]\n",
    "n_classes = 8\n",
    "target_size_per_class = 2500\n",
    "\n",
    "training_df = upsample_function(raw_training_df, minority_classes, n_classes, target_size_per_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.9918    0.9794    0.9856      1118\n",
      "           2     0.9792    0.9900    0.9846      1001\n",
      "           3     0.9990    1.0000    0.9995      1025\n",
      "           4     1.0000    1.0000    1.0000      1002\n",
      "           5     1.0000    1.0000    1.0000       958\n",
      "           6     0.9990    1.0000    0.9995      1025\n",
      "           7     0.9783    0.9930    0.9856      1001\n",
      "           8     0.9929    0.9791    0.9860      1006\n",
      "\n",
      "    accuracy                         0.9925      8136\n",
      "   macro avg     0.9926    0.9927    0.9926      8136\n",
      "weighted avg     0.9925    0.9925    0.9925      8136\n",
      "\n",
      "[[1095   21    1    0    0    0    1    0]\n",
      " [   9  991    0    0    0    1    0    0]\n",
      " [   0    0 1025    0    0    0    0    0]\n",
      " [   0    0    0 1002    0    0    0    0]\n",
      " [   0    0    0    0  958    0    0    0]\n",
      " [   0    0    0    0    0 1025    0    0]\n",
      " [   0    0    0    0    0    0  994    7]\n",
      " [   0    0    0    0    0    0   21  985]]\n"
     ]
    }
   ],
   "source": [
    "# 2 Build-up of the text classifier ##### \n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# classifier = MultinomialNB()\n",
    "classifier = LinearSVC(class_weight='balanced')\n",
    "\n",
    "# Split in test and training data \n",
    "X = vectorizer.fit_transform(training_df['document'])\n",
    "y = training_df['label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "\n",
    "# Train the model in training data\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Test in testing data AND obtaining classification_report\n",
    "y_pred = classifier.predict(X_test)\n",
    "report = classification_report(y_test, y_pred, digits=4)\n",
    "print(report)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3x19162 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 10 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_eval = vectorizer.transform(testing_df[\"document\"])\n",
    "X_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "# 3. Prediction on validation data data\n",
    "X_eval = vectorizer.transform(testing_df[\"document\"])\n",
    "y_eval = classifier.predict(X_eval)\n",
    "\n",
    "for y in y_eval:\n",
    "    print(y)\n",
    "\n",
    "# # # Let's see what accuracy we got\n",
    "# # y_train_pred = classifier.predict(X_train)\n",
    "# # train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "# # print(\"Training accuracy:\", train_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.9943    0.9560    0.9747      1090\n",
      "           2     0.9330    0.9846    0.9581       651\n",
      "           3     0.9980    1.0000    0.9990      1021\n",
      "           4     1.0000    1.0000    1.0000      1027\n",
      "           5     1.0000    1.0000    1.0000       991\n",
      "           6     0.9960    1.0000    0.9980       991\n",
      "           7     0.9902    0.9951    0.9927      1019\n",
      "           8     0.9949    0.9898    0.9924       985\n",
      "\n",
      "    accuracy                         0.9906      7775\n",
      "   macro avg     0.9883    0.9907    0.9894      7775\n",
      "weighted avg     0.9909    0.9906    0.9906      7775\n",
      "\n",
      "[[1042   46    1    0    0    1    0    0]\n",
      " [   6  641    1    0    0    3    0    0]\n",
      " [   0    0 1021    0    0    0    0    0]\n",
      " [   0    0    0 1027    0    0    0    0]\n",
      " [   0    0    0    0  991    0    0    0]\n",
      " [   0    0    0    0    0  991    0    0]\n",
      " [   0    0    0    0    0    0 1014    5]\n",
      " [   0    0    0    0    0    0   10  975]]\n"
     ]
    }
   ],
   "source": [
    "# It seems LinearSVC is not working greatly --> ensemble methods\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# classifier = MultinomialNB()\n",
    "# classifier = LinearSVC(class_weight='balanced')\n",
    "classifier = RandomForestClassifier(random_state=123)\n",
    "\n",
    "# Split in test and training data \n",
    "X = vectorizer.fit_transform(training_df['document'])\n",
    "y = training_df['label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "\n",
    "# Train the model in training data\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Test in testing data AND obtaining classification_report\n",
    "y_pred = classifier.predict(X_test)\n",
    "report = classification_report(y_test, y_pred, digits=4)\n",
    "print(report)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Had I had more time, I would have liked to evaluate:\n",
    "- Other balancing strategies\n",
    "- Other classifier systems\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "836a17164be2d590fd74263af58090dad9ab01a479d389a04c38658626e07a4a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
